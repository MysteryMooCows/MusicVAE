{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDI Exploration\n",
    "\n",
    "Inspiration taken from [this tutorial](https://nbviewer.jupyter.org/github/craffel/midi-dataset/blob/master/Tutorial.ipynb).\n",
    "\n",
    "We use a reduced and cleaned Lakh MIDI dataset [LMD](https://colinraffel.com/projects/lmd/) for this exploration.\n",
    "\n",
    "It is assumed that these files are extracted in a directory called \"clean_midi\" in the folder one level above this (../clean_midi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pretty-midi librosa pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pretty_midi\n",
    "import librosa.display as display\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Local path constants\n",
    "DATA_PATH = '../clean_midi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_name = \"Head Like a Hole.mid\"\n",
    "\n",
    "pm = pretty_midi.PrettyMIDI(os.path.join(DATA_PATH, \"Nine Inch Nails/{}\".format(song_name)))\n",
    "\n",
    "piano_roll = pm.get_piano_roll()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "display.specshow(piano_roll, y_axis='cqt_note', cmap=plt.cm.hot)\n",
    "plt.title(song_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get instrument names from midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for instrument in pm.instruments:\n",
    "    print(instrument)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get notes for specific instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument_no = 3\n",
    "\n",
    "instrument = pm.instruments[instrument_no]\n",
    "instrument_piano_roll = instrument.get_piano_roll()\n",
    "\n",
    "cols = ['start', 'end', 'pitch', 'velocity']\n",
    "\n",
    "note_seq = []\n",
    "for index, note in enumerate(instrument.notes):\n",
    "    note_seq.append([note.start, note.end, note.pitch, note.velocity])\n",
    "    \n",
    "note_df = pd.DataFrame(note_seq, columns=cols)\n",
    "note_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Or as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_seq_np = np.zeros((len(instrument.notes), 4))\n",
    "for index, note in enumerate(instrument.notes):\n",
    "    note_seq_np[index] = [note.start, note.end, note.pitch, note.velocity]\n",
    "\n",
    "note_seq_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to encode the notes as variables over discrete timesteps\n",
    "\n",
    "That means essentially converting the note sequence above to the piano roll we saw earlier.\n",
    "For this to work we:\n",
    "\n",
    "1. ~~Subtract the first start time from all the start/end fields.~~\n",
    "1. ~~(Optional) Find the tempo of the song.~~\n",
    "1. ~~Split the time steps into 32th notes in the given tempo. If no tempo, split it to a static X steps/second.~~\n",
    "1. Encode the note pitches across as dummies denoting whether the pitch is playing at a given timestep or not.\n",
    "1. ~~Remove the start/end from the data (we don't need this information, it needs to be stored in the sequence).~~\n",
    "1. (Optional) Do we need note.velocity? What does this mean to us?\n",
    "1. Should we split this into 2-bar melody pieces?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [pretty_midi.note_number_to_name(n) for n in range(0,128)]\n",
    "def encode_dummies(instrument):\n",
    "    \"\"\" Gonna cheat a little bit by transposing the instrument piano roll. \n",
    "        However, that leaves us with a lot of blank space. \n",
    "    \"\"\"\n",
    "    return pd.DataFrame(instrument.get_piano_roll().T, columns=columns)\n",
    "\n",
    "encoded = encode_dummies(instrument)\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "display.specshow(encoded.T.values, y_axis='cqt_note', cmap=plt.cm.hot)\n",
    "plt.title(song_name)\n",
    "encoded.plot(legend=False) \n",
    "\n",
    "# What's the numbers on the y axis? Is this the velocity? Can maybe ignore this and code it as 1's\n",
    "encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try to forward this to where the action happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_blanks(df):\n",
    "    nonzero = df.apply(lambda s: s != 0)\n",
    "    first_nonzero = df[nonzero].apply(pd.Series.first_valid_index).min()\n",
    "    return df.iloc[int(first_nonzero):]\n",
    "    \n",
    "trimmed = trim_blanks(encoded)\n",
    "plt.figure(figsize=(10, 3))\n",
    "display.specshow(trimmed.T.values, y_axis='cqt_note', cmap=plt.cm.hot)\n",
    "plt.title(song_name)\n",
    "\n",
    "trimmed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For inspection's sake, let's drop all columns that are all 0\n",
    "\n",
    "I want to take a closer look at the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed = trimmed.loc[:, (trimmed != 0).any(axis=0)]\n",
    "trimmed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note Velocity\n",
    "\n",
    "It seems like the piano roll is encoded using note velocity for each step.\n",
    "We should be able to simplify the scores by just [replacing it with a fixed number](http://electronicmusic.wikia.com/wiki/Velocity) that shows up nicely on the visualized output.\n",
    "\n",
    "It might have the effect of the music generated sounding more \"robotic\", but will simplify the problem a lot.\n",
    "\n",
    "Alternatively, we can consider scaling it between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Something about reconstructing a midi from an instrument in transposed piano roll form\n",
    "\n",
    "Let's try to figure out how to do this..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribution and References\n",
    "\n",
    "- Colin Raffel. \"Learning-Based Methods for Comparing Sequences, with Applications to Audio-to-MIDI Alignment and Matching\". [PhD Thesis, 2016](http://colinraffel.com/publications/thesis.pdf).\n",
    "\n",
    "- Colin Raffel and Daniel P. W. Ellis. [Intuitive Analysis, Creation and Manipulation of MIDI Data with pretty_midi](http://colinraffel.com/publications/ismir2014intuitive.pdf). In Proceedings of the 15th International Conference on Music Information Retrieval Late Breaking and Demo Papers, 2014.\n",
    "\n",
    "- [Librosa](https://doi.org/10.5281/zenodo.591533): Audio and music signal analysis in python\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
