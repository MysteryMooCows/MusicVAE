{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AzAJsTx5iY63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/site-packages\n",
      "Requirement already satisfied: pandas>=0.15.2 in /usr/local/lib/python3.6/site-packages (from seaborn)\n",
      "Requirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.6/site-packages (from seaborn)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /usr/local/lib/python3.6/site-packages (from seaborn)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/site-packages (from seaborn)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/site-packages (from pandas>=0.15.2->seaborn)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/site-packages (from pandas>=0.15.2->seaborn)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_jKJvXJNBa_a"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "\n",
    "totalbars=32 #total bars as input\n",
    "NUM_PITCHES=4 # all possible notes to play\n",
    "\n",
    "\n",
    "NOTESPERBAR=16\n",
    "TOTAL_NOTES=NOTESPERBAR*totalbars\n",
    "\n",
    "num_features=NUM_PITCHES #size of input feature vector\n",
    "\n",
    "teacherforcing=False #not used but it will be needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "colab_type": "code",
    "id": "6Am8YawCBqE1",
    "outputId": "bb27b32f-6a1e-4e45-de66-c74622ec3f68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 3 1 3 2 0 2 0 2 0 3 0 3 1 2 1 3 0 2 0 0 2 3 1 1 2 0 3 3 1 1 1 2 0 3 2\n",
      " 2 3 3 0 0 2 2 0 3 1 0 2 1 0 2 1 3 1 0 1 2 2 3 0 3 2 0 0 3 2 0 3 0 1 2 2 2\n",
      " 1 2 2 3 1 1 0 3 3 3 1 1 0 2 0 1 3 2 3 0 0 3 3 2 1 2 2 3 1 0 2 0 1 0 3 3 1\n",
      " 0 1 3 0 2 2 3 3 0 2 3 2 1 2 2 0 3 1 2 2 2 1 1 3 1 3 0 3 2 2 1 0 3 2 2 1 1\n",
      " 0 2 3 3 0 3 0 0 3 3 1 3 2 2 0 1 0 0 0 2 1 2 1 1 0 2 1 0 3 3 0 3 0 3 2 3 2\n",
      " 1 2 2 1 2 1 2 0 0 2 3 2 3 0 3 2 1 1 1 2 1 0 0 3 3 0 0 2 1 0 3 1 2 0 0 3 3\n",
      " 1 2 0 2 1 3 3 3 2 2 2 1 2 0 2 0 3 2 2 0 0 2 3 0 3 2 0 2 3 0 0 2 1 3 2 1 1\n",
      " 3 3 0 0 3 3 3 2 2 1 0 2 2 0 3 2 3 1 0 1 3 2 2 2 3 2 0 3 1 2 0 0 3 2 0 3 1\n",
      " 3 0 2 3 2 1 3 3 2 1 0 3 0 1 3 1 3 2 0 1 3 0 1 0 0 2 1 2 1 3 2 1 2 2 3 1 0\n",
      " 1 1 1 1 3 0 2 0 1 0 3 3 0 1 1 2 3 0 0 2 3 3 0 1 1 3 1 2 1 3 1 1 1 1 3 1 3\n",
      " 2 3 1 2 2 0 2 0 3 3 1 3 1 2 3 1 3 2 1 0 1 1 1 1 1 3 1 1 0 0 3 2 2 2 0 1 2\n",
      " 3 2 3 3 1 3 3 3 1 3 1 1 0 3 3 3 1 3 0 2 1 0 0 0 1 1 3 0 3 1 3 3 0 0 2 1 2\n",
      " 1 2 2 2 3 0 1 1 1 0 1 2 1 3 2 2 2 0 1 2 0 1 1 3 2 2 3 1 3 3 2 0 0 1 2 1 3\n",
      " 1 3 1 3 3 1 2 2 1 0 2 2 0 0 0 3 1 3 1 0 2 0 2 1 1 1 0 3 0 2 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 512, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Generating dummy data\n",
    "a= np.random.randint(NUM_PITCHES, size=TOTAL_NOTES)\n",
    "print(a)\n",
    "data = np.zeros((TOTAL_NOTES, NUM_PITCHES))\n",
    "data[np.arange(TOTAL_NOTES), a] = 1 #generating dummy data\n",
    "\n",
    "\n",
    "#adding 1 dimension, 1x32x4\n",
    "data = data[np.newaxis, :, :]\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PJxAx0yoExnU"
   },
   "outputs": [],
   "source": [
    "#half of this is not yet needed but maybe it will be to visualize the latent space\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display, clear_output\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib nbagg\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(sns.dark_palette(\"purple\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n1jGsBaPFNmy"
   },
   "source": [
    "MODEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "2ASED3VFFKoU",
    "outputId": "540ba87b-7ebd-4565-b6c0-0a3f8ad3ebb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VariationalAutoencoder(\n",
      "  (encoder): LSTM(4, 2048, batch_first=True, bidirectional=True)\n",
      "  (encoderOut): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "  (conductor): LSTM(512, 512)\n",
      "  (decoder): LSTM(1024, 512)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.functional import softplus\n",
    "\n",
    "# define size variables\n",
    "input_size = NUM_PITCHES\n",
    "\n",
    "enc_hidden_size=2048 #hidden size of encoder\n",
    "conductor_hidden_size=1024 #hidden size of decoder\n",
    "\n",
    "\n",
    "decoders_hidden_size=1024 #hidden size of decoder\n",
    "decoders_initial_size=512 #decoder input size\n",
    "\n",
    "n_embeddings=16\n",
    "\n",
    "n_layers_conductor=2\n",
    "n_layers_decoder=3\n",
    "\n",
    "latent_features=512 #latent space dimension\n",
    "\n",
    "sequence_length = 32\n",
    "\n",
    "\n",
    "\n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_features):\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        \n",
    "        self.latent_features = latent_features\n",
    "       \n",
    "        \n",
    "        \n",
    "        #data goes into bidirectional encoder\n",
    "        self.encoder = torch.nn.LSTM(\n",
    "                batch_first = True,\n",
    "                input_size = input_size,\n",
    "                hidden_size = enc_hidden_size,\n",
    "                num_layers = 1,\n",
    "                bidirectional = True)\n",
    "        \n",
    "        #encoded data goes onto connect linear layer. inputs must be*2 because LSTM is bidirectional\n",
    "        #output must be 2*latentspace because it needs to be split into miu and sigma right after.\n",
    "        self.encoderOut = nn.Linear(in_features=enc_hidden_size*2, out_features=latent_features*2)\n",
    "        \n",
    "        \n",
    "        #self.decoderIn = nn.Linear(in_features=latent_features, out_features=conductor_initial_size)\n",
    "        \n",
    "        # The latent code must be decoded into the original image\n",
    "#         self.conductor = torch.nn.LSTM(\n",
    "#                 batch_first=True,\n",
    "#                 input_size=self.latent_features,\n",
    "#                 hidden_size=conductor_hidden_size,\n",
    "#                 num_layers=2,\n",
    "#                 bidirectional = False)\n",
    "                \n",
    "        #Linear layer after leaving condunctor\n",
    "#         self.conductorout = nn.Linear(in_features=TOTAL_NOTES, out_features=2*n_embeddings)    \n",
    "        \n",
    "        \n",
    "        # The latent code must be decoded into the original structure\n",
    "#         self.decoders = [torch.nn.LSTM(\n",
    "#                 batch_first=True,\n",
    "#                 input_size=decoders_initial_size,\n",
    "#                 hidden_size=decoders_hidden_size,\n",
    "#                 num_layers=2,\n",
    "#                 bidirectional = False)] * n_embeddings\n",
    "\n",
    "        # Define the conductor and note decoder\n",
    "        self.conductor = nn.LSTM(decoders_initial_size, decoders_initial_size, num_layers=1)\n",
    "        self.decoder = nn.LSTM(2*decoders_initial_size, decoders_initial_size, num_layers=1)\n",
    "\n",
    "        \n",
    "    #used to initialize the hidden layer of the encoder to zero before every batch\n",
    "    def init_hidden(self, batch_size):\n",
    "        #must be 2 x batch x hidden_size because its a bi-directional LSTM\n",
    "        init = torch.zeros(2, batch_size, enc_hidden_size, device=device)\n",
    "        c0 = torch.zeros(2, batch_size, enc_hidden_size, device=device)\n",
    "    \n",
    "        #2 because has 2 layers\n",
    "        init_conductor = torch.zeros(n_layers_conductor, batch_size, conductor_hidden_size, device=device)\n",
    "        c_condunctor = torch.zeros(n_layers_conductor, batch_size, conductor_hidden_size, device=device)\n",
    "    \n",
    "        #2 because has 2 layers\n",
    "        init_decoders = torch.zeros(n_layers_decoder, batch_size, decoders_hidden_size, device=device)\n",
    "        c_decoders= torch.zeros(n_layers_decoder, batch_size, decoders_hidden_size, device=device)\n",
    "        \n",
    "        \n",
    "        return init,c0,init_conductor,c_condunctor,init_decoders,c_decoders\n",
    "\n",
    "\n",
    "    def forward(self, x): \n",
    "        outputs = {}\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        print(\"Input size\",x.size())\n",
    "        \n",
    "        #creates hidden layer values\n",
    "        h0,c0,hconductor,cconductor,hdecoders,cdecoders = self.init_hidden(batch_size)\n",
    "        \n",
    "        #resets encoder at the beginning of every batch and gives it x\n",
    "        x, hidden = self.encoder(x, ( h0,c0))\n",
    "          \n",
    "        print(\"after enconder\",x.shape)\n",
    "        \n",
    "        #goes from 4096 to 1024\n",
    "        x = self.encoderOut(x)\n",
    "        \n",
    "        print(\"after encoder linear\",x.shape)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Split encoder outputs into a mean and variance vector \n",
    "        mu, log_var = torch.chunk(x, 2, dim=-1)\n",
    "                \n",
    "        # Make sure that the log variance is positive\n",
    "        log_var = softplus(log_var)\n",
    "               \n",
    "        # :- Reparametrisation trick\n",
    "        # a sample from N(mu, sigma) is mu + sigma * epsilon\n",
    "        # where epsilon ~ N(0, 1)\n",
    "                \n",
    "        # Don't propagate gradients through randomness\n",
    "        with torch.no_grad():\n",
    "            batch_size = mu.size(0)\n",
    "            epsilon = torch.randn(batch_size, 1, self.latent_features)\n",
    "            \n",
    "            if cuda:\n",
    "                epsilon = epsilon.cuda()\n",
    "        \n",
    "        #setting sigma\n",
    "        sigma = torch.exp(log_var*2)\n",
    "        \n",
    "        \n",
    "        #generate z - latent space\n",
    "        z = mu + epsilon * sigma\n",
    "        linear_z = nn.Linear(in_features=latent_features, out_features=32)\n",
    "        z = z.permute(0,2,1)\n",
    "        print('z after permutation', z.shape)\n",
    "        z = linear_z(z)\n",
    "        print('z after linear', z.shape)\n",
    "        z = z.permute(2,0,1)\n",
    "        print('z after 2nd permutation', z.shape)\n",
    "        \n",
    "        print(\"z space generated\",z.shape)\n",
    "        \n",
    "        \n",
    "        # Define the conductor and note decoder\n",
    "#         conductor = nn.LSTM(decoders_initial_size, decoders_initial_size)\n",
    "#         decoder = nn.LSTM(2*decoders_initial_size, decoders_initial_size)\n",
    "\n",
    "        # Linear note to note type (classes/pitches)\n",
    "        linear = nn.Linear(decoders_initial_size, NUM_PITCHES)\n",
    "\n",
    "        conductor_hidden = (torch.randn(1, batch_size, decoders_initial_size), torch.randn(1, batch_size, decoders_initial_size))\n",
    "        notes = []\n",
    "\n",
    "        # For the first timestep the note is the embedding\n",
    "        note = torch.zeros(batch_size, batch_size, decoders_initial_size)\n",
    "\n",
    "        # Go through each element in the latent sequence\n",
    "        for i in range(sequence_length):\n",
    "\n",
    "            # Generate an embedding vector\n",
    "            \n",
    "            embedding, conductor_hidden = self.conductor(z[i].view(1, 1, -1), conductor_hidden)    \n",
    "\n",
    "            # Reset the decoder state of each 16 bar sequence\n",
    "            decoder_hidden = (torch.randn(1, batch_size, decoders_initial_size), torch.randn(1, batch_size, decoders_initial_size))\n",
    "\n",
    "            for _ in range(16):\n",
    "                # Concat embedding with previous note\n",
    "                e = torch.cat([embedding, note], dim=-1)\n",
    "\n",
    "                # Generate a single note\n",
    "                note, decoder_hidden = self.decoder(e.view(1, 1, -1), decoder_hidden)\n",
    "\n",
    "                # The note vector must be a probability of the different note types, e.g. (C#, F, E)\n",
    "                notes.append(torch.softmax(linear(note.view(batch_size, -1)), dim=1))\n",
    "\n",
    "        notes = torch.cat(notes)\n",
    "\n",
    "        print('notes:', notes.shape)\n",
    "\n",
    "        \n",
    "        outputs[\"x_hat\"] = notes.unsqueeze(0)\n",
    "        outputs[\"z\"] = z\n",
    "        outputs[\"mu\"] = mu\n",
    "        outputs[\"log_var\"] = log_var\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "net = VariationalAutoencoder(latent_features)\n",
    "\n",
    "# Transfer model to GPU if available\n",
    "if cuda:\n",
    "    net = net.cuda()\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUoxLXafiv1n"
   },
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uEjjddpwdFZH"
   },
   "outputs": [],
   "source": [
    "#directly taken from notebook, probably some adaptation might be needed\n",
    "\n",
    "from torch.nn.functional import binary_cross_entropy\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "\n",
    "def ELBO_loss(y, t, mu, log_var):\n",
    "    # Reconstruction error, log[p(x|z)]\n",
    "    # Sum over features\n",
    "    likelihood = -binary_cross_entropy(y, t, reduction=\"none\")\n",
    "    likelihood = likelihood.view(likelihood.size(0), -1).sum(1)\n",
    "\n",
    "    # Regularization error: \n",
    "    # Kulback-Leibler divergence between approximate posterior, q(z|x)\n",
    "    # and prior p(z) = N(z | mu, sigma*I).\n",
    "    \n",
    "    # In the case of the KL-divergence between diagonal covariance Gaussian and \n",
    "    # a standard Gaussian, an analytic solution exists. Using this excerts a lower\n",
    "    # variance estimator of KL(q||p)\n",
    "    kl = -0.5 * torch.sum(1 + log_var - mu**2 - torch.exp(log_var), dim=1)\n",
    "\n",
    "    # Combining the two terms in the evidence lower bound objective (ELBO) \n",
    "    # mean over batch\n",
    "    ELBO = torch.mean(likelihood) - torch.mean(kl)\n",
    "    \n",
    "    # notice minus sign as we want to maximise ELBO\n",
    "    return -ELBO, kl.sum()\n",
    "\n",
    "\n",
    "\n",
    "# define our optimizer\n",
    "# The Adam optimizer works really well with VAEs.\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_function = ELBO_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sb4f2WjmGAfx"
   },
   "source": [
    "Testing if forward pass works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1007
    },
    "colab_type": "code",
    "id": "mlCBcLJ-GCeN",
    "outputId": "2ea353bc-0884-4a78-8e89-44cf52587026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size torch.Size([1, 512, 4])\n",
      "after enconder torch.Size([1, 512, 4096])\n",
      "after encoder linear torch.Size([1, 512, 1024])\n",
      "z after permutation torch.Size([1, 512, 512])\n",
      "z after linear torch.Size([1, 512, 32])\n",
      "z after 2nd permutation torch.Size([32, 1, 512])\n",
      "z space generated torch.Size([32, 1, 512])\n",
      "notes: torch.Size([512, 4])\n",
      "torch.Size([1, 512, 4])\n",
      "torch.Size([1, 512, 4])\n",
      "torch.Size([32, 1, 512])\n",
      "tensor(1232.2911, grad_fn=<NegBackward>)\n",
      "tensor(40265.0625, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "#setting dummy data\n",
    "x = data\n",
    "\n",
    "\n",
    "\n",
    "#setting input ans tensor variable\n",
    "x = Variable(torch.Tensor(x))\n",
    "\n",
    "if cuda:\n",
    "    x = x.cuda()\n",
    "    \n",
    "    \n",
    "\n",
    "#running forward pass\n",
    "outputs = net(x)\n",
    "\n",
    "\n",
    "#AFTER THIS NOTHING IS DONE YET ------\n",
    "x_hat = outputs[\"x_hat\"]\n",
    "mu, log_var = outputs[\"mu\"], outputs[\"log_var\"]\n",
    "z = outputs[\"z\"]\n",
    "\n",
    "loss, kl = loss_function(x_hat, x, mu, log_var)\n",
    "\n",
    "print(x.shape)\n",
    "print(x_hat.shape)\n",
    "print(z.shape)\n",
    "print(loss)\n",
    "print(kl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot network output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27745962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f99ea77efd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3X2QHOV94PFvT0/Py87OvswKLQsSItqoHjCWLbxYyHJhyyTcgXGJK4o4zlFYYFKxr2zu4svVBXKpOOW6qnPqqpK4SqmkMKYCV7k4sbET4ZIOBTjCUTIIJAscBT02kiVYtMtq19Lu7Lz2dPf9sdPtntmeWUk7vNj9+1Spdrrnmd/z0s/z60ezs7uG53kIIYSIl8S73QAhhBDvPEn+QggRQ5L8hRAihiT5CyFEDEnyF0KIGJLkL4QQMZRczYuVUgXg74ArgZPAp7XWZyPKOcCPmoeva613rqZeIYQQq7Panf/9wFNa603AU83jKBWt9ZbmP0n8QgjxLltt8r8NeKT5+BHg360ynhBCiHfAqt72AUa11lMAWusppdTaDuUySqmXgAbwNa31P6wU+Pnnn/dM08RxHAzD6FjONE08z+N8flLZdV0ADMPoGjOZTOJ5Hq7rrhjXr9+P3al8p/NR7UgkEsFrDMPoGNswjOBct/7AUt879Tt8zq/zfMcz/NpObUgkEjiOs2K8lWL44+DX7Y/TSq/t1pf2vl+IlcYcoF6vk0wmV5xziURixXnsz4VGo4FlWSu226/vfObk+fTlQsueT5/C7TjfuOdznVbqe5jfzvMtfz7Ot0/+ejsf4XXpr4eo9lqWNTsxMXHJSvFWTP5KqSeBSyOe+m8rNzdwhdb6tFJqI/C0UupHWuvj3V4wMzODZVns27ePXC6HaZrLFjvArbfeyrFjx5ifn6der7ck+PBXgKNHj9JoNFizZg1jY2OkUiksy1o2UT73uc8xNTXFCy+8wPz8PKVSqSXx+AzDYOfOnbz++uu89tprlMtlSqUSjuMEF8aPOTU1heu6JJNJEokElmWRSCSCPoXbu2PHDsrlMqdOneK6665j7969kTHT6TRTU1Pk83lyuRz5fD6I2T4pfvCDH1AoFBgbGyOTyZBKpUgkEpim2ZKYpqenGR8fp1gsUq1WW+K0x9RaY1kWw8PDkdfHL79t2zb2798PEJRr77cvm83iOA6JRALDMIKvN910E08++WRQ7vjx41xzzTWYptkSM2oh+XMpm81imiZAZP2O49BoNJbFaO+34zh4nkc+n8c0zSARR9V9//3389nPfpZCocDQ0FBL38Oxr732Wqanp5mbm8N1XWzbxnXdlgW+detWXnjhBb7xjW9w3333YZom5XKZSqUS3BTC86NQKGBZFufOncO2bWzbbtnUhPs1MjKC4zjBTdpvY9Q4jY6OUiqVgvr859v7v23bNqamppicnGwp2x6zWCyyuLjI+vXrSaVSAJHrDWDjxo08/fTTDAwMdN2kbNiwgenpaTzPC/rdqewHPvAB5ubmmJubo9FodNxsVatVkslkcG2iyvjefPNN8vl8cA38dd/u6NGjXHnllaRSqeDa+POrPX6hUGBxcRHbtrnxxhvZt29fZDt27dp1KrJRbVZM/lrrX+/0nFLqLaXUWHPXPwbMdIhxuvn1hFLqGeBaoGvyF0II8fZZ7Xv+e4Bdzce7gH9sL6CUGlZKpZuP1wAfBf51lfUKIYRYhdUm/68BNymlfgLc1DxGKXWdUuqhZpmrgZeUUi8D/5el9/wl+QshxLtoVd/w1VrPAb8Wcf4l4Lebjw8Am1dTjxBCiN6Sn/AVQogYkuQvhBAxJMlfCCFiSJK/EELEkCR/IYSIIUn+QggRQ5L8hRAihiT5CyFEDEnyF0KIGJLkL4QQMSTJXwghYkiSvxBCxJAkfyGEiCFJ/kIIEUOS/IUQIoYk+QshRAxJ8hdCiBiS5C+EEDG0qj/j6FNK3Qx8HTCBh7TWX2t7Pg08CkwAc8Bvaq1P9qJuIYQQF27VO3+llAn8BXAL8D7gt5RS72srdi9wVmv9q8CfAX+y2nqFEEJcvF687bMVeE1rfUJrXQe+BdzWVuY24JHm4+8Av6aUMnpQtxBCiIvQi+R/OfBG6HiyeS6yjNa6AcwDIz2oWwghxEUwPM9bVQCl1G8A/1Zr/dvN47uArVrr+0JljjbLTDaPjzfLzHWK++yzz3qpVIr5+XkSiQSGYWAYy/+zMDg4SLVaxXEcXNft2tZqtYrneSSTSSzL6hhzzZo12LZNqVQK4nYap6GhIer1OrVaDdd1W8qGX2PbdvA4XG9U/fl8Htd1qdfr9PX1MT8/vyye/1rbtjFNk0QigWmawfn2sqVSCdM0sSxr2XiG22DbNul0GsdxlsVoP65WqxiGQTKZ7NgXgFwux8LCQku7O0kkWvcjftmBgYGWGLVajWw221KmU1zbtjEMI+h3VHy/f+e7HjzPwzTNjnPINzk5ycjICMlkMigfpa+vD9u2aTQaHdvS19dHqVRidnaWtWvXYhhGy5xrL59MJjEMo+McDh/719A/161PlmV1XRO+XC6HbdvYtt21rOu6OI5DKpXqWi9AOp1mYWEhmOudpFIpGo3GeV3TbDZLo9EI5nyn8q7rRq6tKPV6HdM0g7UJ0WNaqVRIpVJBmW71J5PJoI0DAwPMz89Hll2zZs2hiYmJ61ZqYy++4TsJrA8drwNOdygzqZRKAoPAz7oFPXfuHJZlsW/fPnK5XMsght16660cP36c+fl56vV6cAOISghHjx6l0WiwZs0axsbGSKVSwU0Afj7xP/e5zzE1NcWrr77K/Pw8pVIp8sZiGAY7d+5kbm6O1157jXK5vOyG4cecmprCdV2SySSJRCJIwu0TwzAMduzYQblc5tSpU1x33XU88cQTkTHT6TRTU1Pk83lyuRz5fD6I2T4pfvCDH1AoFBgbGyOTyQQTrj2BTU9PMz4+TrFYDG6WvvaYWmssy2J4eDjy+vjlt23bxv79+wGCcp0WRDabxXGcIFH7X2+66SaefPLJoNzx48e55pprWhZYVHIHmJmZwbIsstlskDSi6ncch0ajsSxGe7/9BZjP54MbalRfAO6//34++9nPUigUGBoaaul7OPa1117L9PQ0c3NzuK6LbdvLNhNbt27lhRde4Bvf+Ab33XcfpmlSLpepVCq4rrss2RUKBSzL4ty5cy1JOOpmMTIyguM4OI7TMj5R4zQ6OkqpVArq859v7/+2bduYmppicnKypWx7zGKxyOLiIuvXryeVSgF03Mht3LiRp59+moGBga6JeMOGDUxPT+N5XtDvTmU/8IEPMDc3x9zcHI1GI6g7arOTTCaDaxNVxvfmm2+Sz+eDa+Cv+3ZHjx7lyiuvJJVKBdcmvPEKxy8UCiwuLmLbNjfeeCP79u2LbMeuXbsi29SuF8n/RWCTUupXgDeBzwD/vq3MHmAX8APgDuBprfXq/sshhBDioq36Pf/me/hfAp4AXgX+Xmt9VCn1VaXUzmaxbwIjSqnXgP8M3L/aeoUQQly8nnzOX2u9F9jbdu6PQo+rwG/0oi4hhBCrJz/hK4QQMSTJXwghYkiSvxBCxJAkfyGEiCFJ/kIIEUOS/IUQIoYk+QshRAxJ8hdCiBiS5C+EEDEkyV8IIWJIkr8QQsSQJH8hhIghSf5CCBFDkvyFECKGJPkLIUQMSfIXQogYkuQvhBAxJMlfCCFiSJK/EELEUE/+hq9S6mbg64AJPKS1/lrb83cD/xN4s3lqt9b6oV7ULYQQ4sKtOvkrpUzgL4CbgEngRaXUHq31v7YV/Tut9ZdWW58QQojV68XOfyvwmtb6BIBS6lvAbUB78r8g2WwWgHQ6TbVaxXVdXNcFwPO8oNz+/fsZHBxkYGAAx3GwbTso63leS9kPfvCD1Ot1TNPEsiwMwwjKhd1zzz1cddVVFAoFAEzTxDTNyHYqpbjnnnsYHh4mmUxiWRaJRALDMEgkfv6u2h//8R8zNzfHyy+/TLlcplKpdOzT4cOH8TyPbDZLIpFg3bp1ABiG0VL37bffzsmTJ5mamqJarVKr1YL+tJe9++67qVarFItFGo1GUK/PLz87O4vruqxfvz64Bu3t85mmyejoKCMjIy3j0172gQce4POf/zzJZDKoxy/TXta/PgMDA6RSKSzLApbmwzXXXBOUu/POO/nnf/5nHMdZ1q52+/fvZ/PmzSilyGQyy8bGt337dg4cOIDjOMG188uGX9NoNCgUCnieh23bNBoNPM/DcZxl/XnooYcoFovYth3M40ajsazvf/iHf8jw8DAbN24km83S19eHaZokk8mgfn9OPffcc2itmZ+fZ3Z2lkqlguM4y+byqVOnMAyDsbExLMsK5nxU/z/84Q8zNTXFzMxM0J/2NgI89thj2LbNDTfcwMDAAOl0GsMwgrUWft33vvc9TNOkv7+fZDKJaZrBmgv75Cc/ycmTJzl58iTVarWlje1tzeVybNiwIajTtu3Itm7atIlTp06RSCTIZrPBWEb1/8iRI5imSTabDeZHVP2zs7OsXbuW/v7+jnPId9lll1Gv17FtO8g3fv/9/ADw+OOPc+utt1IoFBgZGcGyrGDdR83BdDpNJpPBsizGxsY6Xs/zYUQt6guhlLoDuFlr/dvN47uA68O7/ObbPv8DOAP8GPiy1vqNbnEPHDjgmabJwsLCsiQe5g+qP1DdyvrPrTRgi4uLZDKZYOF1G6M33niDNWvWBBe2U+w1a9bQaDRakn6nuP7iSCQS5HI5yuVyZLnh4WFqtVqwANoXVZhpmh0TVFi5XMY0TVKp1IqTqlQqYVlWS1KH5eM1OzvLJZdcAvx8Ine7Rv4CCS+SdDpNrVYLyvX19VEsFrv2JVy/v7A73cRhKbGUSqXIm2d7G8Nzo1OihKX56Y95t7l57tw5TNMknU639D3cDr99IyMjVKtVHMcJbuRRcf3x8q9ltz7lcjls225JplHOnj2L53n09/e3rLvw2Phs2wYI1gYsT+YA/f391Ot16vX6imOfy+WoVCot9UW1t7+/n4WFhZY12SmufzNuT7btarVacANdSfiG6B9HjcHk5CRDQ0ORN6eoevx4/f39lEqlyLoHBgYOTUxMXLdSG3ux848aifar8Tjwt1rrmlLqC8AjwI3dgvod279/fzDBo3bJo6Oj573zd1132c6/PR7AgQMHWnb+3ZLql7/85Y47//DFu/fee5mbm+P48eMr7vwrlUqw87/++us5cuQIsLqd//Dw8Hnt/A8fPkyhUGD9+vVBgosaI4CDBw8yNja24s7/wQcfXPXOf3x8nBMnTgTltmzZwiuvvHJeO/+HH3442PnncrmuO//Dhw9f9M4/Kglfeumly3b+Udf88ccfX3Hnv3XrVg4ePMhdd931tuz833rrrZ7u/E+fPh2582+3Y8cO3njjDU6ePLlsc9ZefuvWrbzyyisr7vy3b9/Oc889RyKRCG76nXb+MzMzwc6/fe2Gy544cYK1a9ee18bIsqzz2vk/8MADy3b+yWSy486/VqthGAbbt2/nxRdfjOzPJz7xia5t8/Ui+U8C60PH64DT4QJa67nQ4TeAP+lBvUIIIS5SLz7q+SKwSSn1K0qpFPAZYE+4gFJqLHS4E3i1B/UKIYS4SKve+WutG0qpLwFPsPRRz4e11keVUl8FXtJa7wH+o1JqJ9AAfgbcvdp6hRBCXLyefM5fa70X2Nt27o9Cjx8AHuhFXUIIIVZPfsJXCCFiSJK/EELEkCR/IYSIIUn+QggRQ5L8hRAihiT5CyFEDEnyF0KIGJLkL4QQMSTJXwghYkiSvxBCxJAkfyGEiCFJ/kIIEUOS/IUQIoYk+QshRAxJ8hdCiBiS5C+EEDEkyV8IIWJIkr8QQsRQT/6Mo1LqYeBTwIzW+v0RzxvA14FPAmXgbq314V7ULYQQ4sL1auf/18DNXZ6/BdjU/Pc7wF/2qF4hhBAXoSfJX2v9LPCzLkVuAx7VWnta6+eBIaXUWC/qFkIIceEMz/N6EkgpdSXw/Q5v+3wf+JrW+rnm8VPA72utX+oU78CBA55pmiwsLOB5Hp3aaVkWpmmSSCzdx7qV9Z8zDAPDMDr2ZXFxkUwmQzKZDF7XyRtvvMGaNWswTTOIGxV7zZo1NBoNKpUKruvium7HuK7rApBIJMjlcpTL5chyw8PD1Go1bNvG87zgdVFM08TzPBzH6dqfcrmMaZqkUqmuYwRQKpWwLItkMtlStj3+7Owsl1xyCUBQrts1MgyDRCJBIpEIyqfTaWq1WlCur6+PYrHYtS/h+rPZLJlMBtM0O5bL5XKUSqWgDZ14ntcyN/w2RLXFsqxgzLvNzXPnzmGaJul0uqXv4Xb47RsZGaFareI4Do1Go+Nc8sfLv5bd+pTL5bBtO5hLnZw9exbP8+jv729Zd+Gx8dm2DRCsDSCyDf39/dTrder1+opjn8vlqFQqLfVFtbe/v5+FhYWWNdkpbqPRAAj60qlcrVbDsqwV14UfI9y2cP3h109OTjI0NIRpmsE66jZWfrz+/n5KpVJk3QMDA4cmJiauW6mNPXnP/zxEjVbXVet3bP/+/cEE95Nb+GKPjo4yODjIwMAAjuNg23ZLcg2XdV2Xer2OaZotF7F98hw4cICrrrqKQqEQvK6TL3/5y9xzzz0MDw+TTCaxLCty4d57773Mzc1x/PhxyuVyy02gvQ2VSgXP88hms1x//fUcOXJkaRDbJsPtt9/OyZMnmZqaolqtUqvVgn63lx0eHqZarVIsFoPxDPPLHz58mEKhwPr164MEFzVGAAcPHmRsbIyRkZGWpNpe9sEHH+Tzn/98y02iU8L0r8/AwACpVArLsgAYHx/nxIkTQbktW7bwyiuv4DjOsna1e/jhh9m8eTNKKXK5XMfFu337dg4fPozjOMsSQfg1jUaDQqGA53nYtk2j0Qhuvu39ufTSSykWi9i2TbVa7XjNH3/8cYaHh9m4cSPZbJa+vr4gIfj1b926lYMHD3LXXXehtWZ+fp7Z2VkqlQqO4yyr/9SpUxiGwdjYGJZlBXM+qv8f/vCHeeutt5iZmQn6095GgMceewzbtrnhhhsYGBggnU63JLrw606fPo1pmvT395NMJltuAmE7duzgjTfe4OTJk8s2Z+3lt27dyiuvvBLUGb5Zhdu6fft2nnvuORKJRHDTb0+uvpmZGUzTJJvNLlu74bInTpxg7dq157UxsiyLer2ObdtBvvH7H97UPPDAA9x6660UCgVGRkaCzZS/AQi3wTAMarUahmGwfft2Xnzxxcj+fOITn+jaNt879WmfSWB96HgdcPodqlsIIUSbd2rnvwf4klLqW8D1wLzWeuodqlsIIUSbXn3U82+BHcAapdQk8BXAAtBa/xWwl6WPeb7G0kc97+lFvUIIIS5OT5K/1vq3VnjeA77Yi7qEEEKsnvyErxBCxJAkfyGEiCFJ/kIIEUOS/IUQIoYk+QshRAxJ8hdCiBiS5C+EEDEkyV8IIWJIkr8QQsSQJH8hhIghSf5CCBFDkvyFECKGJPkLIUQMSfIXQogYkuQvhBAxJMlfCCFiSJK/EELEkCR/IYSIoV79Dd+HgU8BM1rr90c8vwP4R+CnzVPf1Vp/tRd1CyGEuHA9Sf7AXwO7gUe7lPl/WutP9ag+IYQQq9CTt3201s8CP+tFLCGEEG8/w/O8ngRSSl0JfL/L2z6PAZPAaeC/aK2Pdot34MABzzRNyuXyUkMNI7LczMwMqVSKdDqNYRgt5dpfYxgGiUQC13VxXRfP8yLjZrNZbNsOjv0xihqrcrmMYRhYlhXEj6r73Llz9PX1YVlWt24D4LpuEGNwcJD5+fnIdhqGQSaTwXEcPM/DcZyO7RwZGaFarVKtVvE8r2Of/HExTXPZeLYbGhoKYvptjup7NpsNxtxva7gNYblcDsdxaDQaQVsA8vk8xWIxKNff30+5XG4p08kll1xCrVajXC4H9UdJJpMtbevUd9u2cV03GKNu8vl8MD7hMYqqO9y2qDb6c8FxHKrVKolEgmQySSKRiLxWjUYD0zQBVryW4WvuH0e1IZvNYhgG9Xo9skz42K+7W58AHMcJ1s1K13J4eJjFxUUajUbXa9RoNEilUucVs9FoAK1jFBXXsqwV56+vr68vmMftZcOPR0ZGWFhYWPHaA0HuAhgYGGBhYSGyXKFQODQxMXFdtz5D7972WclhYIPWelEp9UngH4BN3V5QLpdJJBIcPHiQZDLZMbHu3r2byy67jPHxcVKpFKlUKriI7RcwnU6Ty+VYXFykVCoFk6d98Vx11VW89dZbJBIJPM8LLqA/ScKL+MiRIySTSUZHR8lkMmSzWRKJRMuiA9izZw+bN29m3bp1GIbRddFUKhVg6WLv3LmTvXv3Rk7KTCbD+Pg4i4uLVKtVSqUSrusG7QzH3LVrFz/96U/58Y9/jG3b2LYd3DDCk9OPkc/nW8Yyqp233347r7/+OseOHaNerwfn25Pi1VdfTblcplwuMz8/T6PRWJbcfRMTE5RKJaanp6nVakFfPv7xj/PMM88EcT/ykY/w8ssvUy6Xg7rbx9V//IUvfIHjx49z+PBhisVi5A3AMAyGhoZwXZdarYbjOB3n0enTp6lUKgwODgbJ16+vPe6NN97IsWPHKJVKwXX16wvHHhwcDJJa+03Sd8stt7Bv3z6KxSLHjh2jr6+PQqFAX18fyWQy2ID4/2ZnZ+nv78c0TUzTxLKsYK63q1QqDA8PY1lWMIeirs/mzZtJJBKcOnUK27aXtTNcPp/PA0vJPdyn9rjFYpG+vj7g55uPTgnzjjvu4MiRI5w5cwbXdTv2Z2ZmhiuuuGLFGxTA7OwshmGQSqWCtetf07CxsbFg/ob7HhXzQx/6EGfPnmV2djaY736ZcP648847OXToEIuLi8E8bt8k+K/LZDLBZvimm27iySefXNZGgE9/+tOR59u9I5/20VovaK0Xm4/3ApZSas07UbcQQojl3pHkr5S6VCllNB9vbdY7907ULYQQYrlefdTzb4EdwBql1CTwFcAC0Fr/FXAH8B+UUg2gAnxGa92bbzYIIYS4YD1J/lrr31rh+d0sfRRUCCHEe4D8hK8QQsSQJH8hhIghSf5CCBFDkvyFECKGJPkLIUQMSfIXQogYkuQvhBAxJMlfCCFiSJK/EELEkCR/IYSIIUn+QggRQ5L8hRAihiT5CyFEDEnyF0KIGJLkL4QQMSTJXwghYkiSvxBCxJAkfyGEiKFV/xlHpdR64FHgUsAFHtRaf72tjAF8HfgkUAbu1lofXm3dQgghLk4vdv4N4Pe01lcD24AvKqXe11bmFmBT89/vAH/Zg3qFEEJcpFUnf631lL+L11oXgVeBy9uK3QY8qrX2tNbPA0NKqbHV1i2EEOLiGJ7n9SyYUupK4Fng/VrrhdD57wNf01o/1zx+Cvh9rfVLnWIdOHDAM02Tcrm81FDDiCw3MzNDKpUinU5jGEZLufbXGIZBIpHAdV1c18XzvMi42WwW27aDY3+MosaqXC5jGAaWZQXxo+o+d+4cfX19WJbVqcsB13WDGIODg8zPz0e20zAMMpkMjuPgeR6O43Rs58jICNVqlWq1iud5Hfvkj4tpmsvGs93Q0FAQ029zVN+z2Www5n5bw20Iy+VyOI5Do9EI2gKQz+cpFotBuf7+fsrlckuZTi655BJqtRrlcjmoP0oymWxpW6e+27aN67rBGHWTz+eD8QmPUVTd4bZFtdGfC47jUK1WSSQSJJNJEolE5LVqNBqYpgmw4rUMX3P/OKoN2WwWwzCo1+uRZcLHft3d+gTgOE6wbla6lsPDwywuLtJoNLpeo0ajQSqVOq+YjUYDaB2jqLiWZa04f319fX3BPG4vG348MjLCwsLCitceCHIXwMDAAAsLC5HlCoXCoYmJieu69Rl68J6/TynVDzwG/G448TdFXaGuV6RcLpNIJDh48CDJZLJjYt29ezeXXXYZ4+PjpFIpUqlUcBHbL2A6nSaXy7G4uEipVAomT/viueqqq3jrrbdIJBJ4nhdcQH+ShBfxkSNHSCaTjI6OkslkyGazJBKJlkUHsGfPHjZv3sy6deswDKProqlUKsDSxd65cyd79+6NnJSZTIbx8XEWFxepVquUSiVc1w3aGY65a9cufvrTn/LjH/8Y27axbTu4YYQnpx8jn8+3jGVUO2+//XZef/11jh07Rr1eD863J8Wrr76acrlMuVxmfn6eRqOxLLn7JiYmKJVKTE9PU6vVgr58/OMf55lnngnifuQjH+Hll1+mXC4HdbePq//4C1/4AsePH+fw4cMUi8XIG4BhGAwNDeG6LrVaDcdxOs6j06dPU6lUGBwcDJKvX1973BtvvJFjx45RKpWC6+rXF449ODgYJLX2m6TvlltuYd++fRSLRY4dO0ZfXx+FQoG+vj6SyWSwAfH/zc7O0t/fj2mamKaJZVnBXG9XqVQYHh7GsqxgDkVdn82bN5NIJDh16hS2bS9rZ7h8Pp8HlpJ7uE/tcYvFIn19fcDPNx+dEuYdd9zBkSNHOHPmDK7rduzPzMwMV1xxxYo3KIDZ2VkMwyCVSgVr17+mYWNjY8H8Dfc9KuaHPvQhzp49y+zsbDDf/TLh/HHnnXdy6NAhFhcXg3ncvknwX5fJZILN8E033cSTTz65rI0An/70pyPPt+vJp32UUhZLif9vtNbfjSgyCawPHa8DTveibiGEEBeuF5/2MYBvAq9qrf+0Q7E9wJeUUt8CrgfmtdZTq61bCCHExenF2z4fBe4CfqSUOtI89wfAFQBa678C9rL0Mc/XWPqo5z09qFcIIcRFWnXyb34Tt+t3vbTWHvDF1dYlhBCiN+QnfIUQIoYk+QshRAxJ8hdCiBiS5C+EEDEkyV8IIWJIkr8QQsSQJH8hhIghSf5CCBFDkvyFECKGJPkLIUQMSfIXQogYkuQvhBAxJMlfCCFiSJK/EELEkCR/IYSIIUn+QggRQ5L8hRAihiT5CyFEDPXiD7ivBx4FLgVc4EGt9dfbyuwA/hH4afPUd7XWX11t3UIIIS5OL/6AewP4Pa31YaVUHjiklPonrfW/tpX7f1rrT/WgPiGEEKu06rd9tNZTWuvDzcdF4FXg8tXGFUII8fbh3sRwAAAOXklEQVQxPM/rWTCl1JXAs8D7tdYLofM7gMeASeA08F+01ke7xfrhD3/oua4LgOu6dGqnYRgA2LaN53nBcZR0Oh3EazQaeJ4XxA3HP3PmDKlUikwmg2mamKaJYRiRsYeGhqjVah1j+fw+JBKJjrF81WqVRCJBMpkkkeh8fz5z5gzpdJpkMhnE7BS3VCqRTqexLKtjPICBgQGq1WownmHtsU3TbGlft7nkOA6GYQTlO7WzXC6TSCSCcn7MVCpFrVYLyhWLRfr7+zFNc8X622N1Mj8/Tz6fjxzz8GvT6TSe51Gv11vOR/Upk8m0tLsTf551m+umaQbjGB5Pv972+i3LwnGclpidrmmxWAzmXLd5lE6ncRxn2fqJqr9SqWBZVrB+OqlWq2QymaB93cpalkW9Xl9xHvnzo73P3cbWMIyuc8Qf//CY+9qPbdtuGcdO+SGfzwfXqNu192NalhXE7TRWhmEcmpiYuK5joKZevO0DgFKqn6UE/7vhxN90GNigtV5USn0S+AdgU9eGJZPBBGtPrmH+hH3zzTdxXbfrRBsfHweWJtvZs2ep1+vU6/Vlg7579242bNiAUorBwUGGhoZIJpORC2PLli2cOHEiSAR+LP/GBQR9qFar5PP5FRfEiRMnyOVyjIyMkMvlcF03ckF++9vfZuPGjaxdu5ZkMkk6nW5JsPDzSfn8888zPj7O6OhoZDL0H19zzTX85Cc/4cyZM9i23RKjfcENDg6SzWaDidh+jcKP5+fngxtqIpHoeEM9evQo/f39ZLNZPM/DcRw8z+OKK67g1KlTQbmnnnqKj33sY+RyuaD+qMVjGEYwLv58Ci/IsCeeeIIdO3aQyWRaYgLBV8/zGB8fp16vMzk5SaPRwHXdlhtWuE9KKaanp1fcHAwPDzM0NESlUsFxHBzHWdaPfD5PsVjENM1gPHO5XJAQ2m9ao6OjzM/PBzH9/rfHBThw4AD9/f2MjIxgWVYQs93GjRspFovMzs5i2zaNRgNg2abGMAyOHj3K2rVrKRQKLePTTmvNpk2bgnFujxN2+eWXc/LkyWAeJZPJyHJPP/00N9xwA4ZhBBuZ9vkRXqODg4Mkk8mWJNw+VoVCgYWFhWAT1e3GOz09HZRzXZd6vR6Mf7jeHTt2cO7cOSqVCrVaLZjvUSYnJ1m/fj2maQY39qhr5I/JSnryaR+llMVS4v8brfV325/XWi9orRebj/cCllJqTS/qFkIIceFWnfyVUgbwTeBVrfWfdihzabMcSqmtzXrnVlu3EEKIi9OLt30+CtwF/EgpdaR57g+AKwC01n8F3AH8B6VUA6gAn9Fa9+6bDUIIIS7IqpO/1vo5oPN3aJbK7AZ2r7YuIYQQvSE/4SuEEDEkyV8IIWJIkr8QQsSQJH8hhIghSf5CCBFDkvyFECKGJPkLIUQMSfIXQogYkuQvhBAxJMlfCCFiSJK/EELEkCR/IYSIIUn+QggRQ5L8hRAihiT5CyFEDEnyF0KIGJLkL4QQMSTJXwghYmjVf8ZRKZUBngXSzXjf0Vp/pa1MGngUmGDpD7f/ptb65GrrFkIIcXF6sfOvATdqrT8IbAFuVkptaytzL3BWa/2rwJ8Bf9KDeoUQQlykVSd/rbWntV5sHlrNf15bsduAR5qPvwP8mlKq6x99F0II8fbpyXv+SilTKXUEmAH+SWv9QluRy4E3ALTWDWAeGOlF3UIIIS6c4Xntm/SLp5QaAr4H3Ke1/pfQ+aPAv9VaTzaPjwNbtdZznWL98Ic/9FzXBcB1XTq10zCW/gNh2zae5wXHUdLpdBCv0WjgeV4QNxz/zJkzpFIpMpkMpmlimiaGYUTGHhoaolardYzl8/uQSCQ6xvJVq1USiQTJZJJEovP9+cyZM6TTaZLJZBCzU9xSqUQ6ncayrI7xAAYGBqhWq8F4hrXHNk2zpX3d5pLjOBiGEZTv1M5yuUwikQjK+TFTqRS1Wi0oVywW6e/vxzTNFetvj9XJ/Pw8+Xw+cszDr02n03ieR71ebzkf1adMJtPS7k78edZtrpumGYxjeDz9etvrtywLx3FaYna6psViMZhz3eZROp3GcZxl6yeq/kqlgmVZwfrppFqtkslkgvZ1K2tZFvV6fcV55M+P9j53G1vDMLrOEX/8w2Puaz+2bbtlHDvlh3w+H1yjbtfej2lZVhC301gZhnFoYmLiuo6Bmlb9Dd8wrfU5pdQzwM3Av4SemgTWA5NKqSQwCPysa8OSyWCCtSfXMH/Cvvnmm7iu23WijY+PA0uT7ezZs9Trder1+rJB3717Nxs2bEApxeDgIENDQySTyciFsWXLFk6cOBEkAj+Wf+MCgj5Uq1Xy+fyKC+LEiRPkcjlGRkbI5XK4rhu5IL/97W+zceNG1q5dSzKZJJ1OtyRY+PmkfP755xkfH2d0dDQyGfqPr7nmGn7yk59w5swZbNtuidG+4AYHB8lms8FEbL9G4cfz8/PBDTWRSHS8oR49epT+/n6y2Sye5+E4Dp7nccUVV3Dq1Kmg3FNPPcXHPvYxcrlcUH/U4jEMIxgXfz6FF2TYE088wY4dO8hkMi0xgeCr53mMj49Tr9eZnJyk0Wjgum7LDSvcJ6UU09PTK24OhoeHGRoaolKp4DgOjuMs60c+n6dYLGKaZjCeuVwuSAjtN63R0VHm5+eDmH7/2+MCHDhwgP7+fkZGRrAsK4jZbuPGjRSLRWZnZ7Ftm0ajAbBsU2MYBkePHmXt2rUUCoWW8WmntWbTpk3BOLfHCbv88ss5efJkMI+SyWRkuaeffpobbrgBwzCCjUz7/Aiv0cHBQZLJZEsSbh+rQqHAwsJCsInqduOdnp4OyrmuS71eD8Y/XO+OHTs4d+4clUqFWq0WzPcok5OTrF+/HtM0gxt71DXyx2Qlq37bRyl1SXPHj1IqC/w6cKyt2B5gV/PxHcDTWuve/ZdDCCHEBenFzn8MeEQpZbJ0M/l7rfX3lVJfBV7SWu8Bvgn8L6XUayzt+D/Tg3qFEEJcpFUnf631K8C1Eef/KPS4CvzGausSQgjRG/ITvkIIEUOS/IUQIoYk+QshRAxJ8hdCiBiS5C+EEDEkyV8IIWJIkr8QQsSQJH8hhIghSf5CCBFDkvyFECKGJPkLIUQMSfIXQogYkuQvhBAxJMlfCCFiSJK/EELEkCR/IYSIIUn+QggRQ5L8hRAihiT5CyFEDK36b/gqpTLAs0C6Ge87WuuvtJW5G/ifwJvNU7u11g+ttm4hhBAXZ9XJH6gBN2qtF5VSFvCcUmqf1vr5tnJ/p7X+Ug/qE0IIsUqrTv5aaw9YbB5azX/eauMKIYR4+xiet/o8rZQygUPArwJ/obX+/bbn7wb+B3AG+DHwZa31G91iHjp06AxwatWNE0KIeNkwMTFxyUqFepL8fUqpIeB7wH1a638JnR8BFrXWNaXUF4BPa61v7FnFQgghLkhPP+2jtT4HPAPc3HZ+Tmtdax5+A5joZb1CCCEuzKqTv1LqkuaOH6VUFvh14FhbmbHQ4U7g1dXWK4QQ4uL14tM+Y8Ajzff9E8Dfa62/r5T6KvCS1noP8B+VUjuBBvAz4O4e1CuEEOIi9fQ9fyGEEL8Y5Cd8hRAihiT5CyFEDPXiPf+eU0rdDHwdMIGHtNZfe5eb9LZRSj0MfAqY0Vq/v3muAPwdcCVwkqWPxp5VShksjcsngTJwt9b68LvR7l5SSq0HHgUuBVzgQa311+M0Dp1+TYpS6leAbwEF4DBwl9a6rpRKszRmE8Ac8Jta65PvSuN7rPn9w5eAN7XWn4rpGJwEioADNLTW1/V6Pbzndv7NC/8XwC3A+4DfUkq9791t1dvqr2n7aCxwP/CU1noT8FTzGJbGZFPz3+8Af/kOtfHt1gB+T2t9NbAN+GLzmsdpHPxfk/JBYAtws1JqG/AnwJ81x+AscG+z/L3AWa31rwJ/1iz3y+I/0fqJwDiOAcAntNZbtNbXNY97uh7ec8kf2Aq8prU+obWus3THv+1dbtPbRmv9LEufgAq7DXik+fgR4N+Fzj+qtfaavztpqO1jtL+QtNZT/k5Fa11kaeFfTozGodmXqF+TciPwneb59jHwx+Y7wK81d4C/0JRS64BbgYeaxwYxG4Mueroe3ovJ/3Ig/KsfJpvn4mRUaz0FS4kRWNs8/0s/NkqpK4FrgReI2TgopUyl1BFgBvgn4DhwTmvdaBYJ9zMYg+bz88DIO9vit8WfA/+Vpbf/YKlPcRsDWLrx71dKHVJK/U7zXE/Xw3sx+UfdueXzqEt+qcdGKdUPPAb8rtZ6oUvRX8px0Fo7WustwDqW/gd8dUQxv5+/dGOglPK/93UodLpbP3/pxiDko1rrD7H0ls4XlVIf61L2osbhvZj8J4H1oeN1wOl3qS3vlrf8/7Y1v840z//Sjk3z14E/BvyN1vq7zdOxGwdo+TUp21j6L7z/wYxwP4MxaD4/yPK3D3/RfBTY2fxm57dYervnz4nXGACgtT7d/DrD0u9L20qP18N7Mfm/CGxSSv2KUioFfAbY8y636Z22B9jVfLwL+MfQ+c8qpYzmNwPn/f8G/iJrvk/7TeBVrfWfhp6KzTh0+DUprwL/F7ijWax9DPyxuQN4uvnr1X9haa0f0Fqv01pfydK6f1prfScxGgMApVROKZX3HwP/BvgXerwe3nMf9dRaN5RSXwKeYOmjng9rrY++y8162yil/hbYAaxRSk0CXwG+Bvy9Uupe4HXgN5rF97L0ca7XWPpI1z3veIPfHh8F7gJ+1HzPG+APiNc4dPo1Kf8KfEsp9d+BH7J0k6T59X8ppV5jabf7mXej0e+Q3ydeYzAKfE8pBUs5+n9rrf+PUupFerge5Nc7CCFEDL0X3/YRQgjxNpPkL4QQMSTJXwghYkiSvxBCxJAkfyGEiCFJ/kIIEUOS/IUQIob+P4JsGGpvfC/aAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_np = x_hat.detach().numpy()\n",
    "x_np = x_np.squeeze(0)\n",
    "# x_np.shape\n",
    "print(x_np[0][0])\n",
    "plt.imshow(x_np.T, aspect='auto', cmap='Greys',  interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f99debd8550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_to_display = data.squeeze(0)\n",
    "# data_to_display.shape\n",
    "print(data_to_display[0][0])\n",
    "plt.imshow(data_to_display.T, aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "num_epochs = 100\n",
    "tmp_img = \"tmp_vae_out.png\"\n",
    "show_sampling_points = False\n",
    "\n",
    "train_loss, valid_loss = [], []\n",
    "train_kl, valid_kl = [], []\n",
    "\n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    batch_loss, batch_kl = [], []\n",
    "    net.train()\n",
    "    \n",
    "    # Go through each batch in the training dataset using the loader\n",
    "    # Note that y is not necessarily known as it is here\n",
    "    for x, m in train_loader:\n",
    "        x = Variable(x)\n",
    "        \n",
    "        # This is an alternative way of putting\n",
    "        # a tensor on the GPU\n",
    "        x = x.to(device)\n",
    "        \n",
    "        outputs = net(x)\n",
    "        x_hat = outputs['x_hat']\n",
    "        mu, log_var = outputs['mu'], outputs['log_var']\n",
    "\n",
    "        elbo, kl = loss_function(x_hat, x, mu, log_var)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        elbo.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss.append(elbo.item())\n",
    "        batch_kl.append(kl.item())\n",
    "\n",
    "    train_loss.append(np.mean(batch_loss))\n",
    "    train_kl.append(np.mean(batch_kl))\n",
    "\n",
    "    # Evaluate, do not propagate gradients\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        \n",
    "        # Just load a single batch from the test loader\n",
    "        x, y = next(iter(test_loader))\n",
    "        x = Variable(x)\n",
    "        \n",
    "        x = x.to(device)\n",
    "        \n",
    "        outputs = net(x)\n",
    "        x_hat = outputs['x_hat']\n",
    "        mu, log_var = outputs['mu'], outputs['log_var']\n",
    "        z = outputs[\"z\"]\n",
    "\n",
    "        elbo, kl = loss_function(x_hat, x, mu, log_var)\n",
    "        \n",
    "        # We save the latent variable and reconstruction for later use\n",
    "        # we will need them on the CPU to plot\n",
    "        x = x.to(\"cpu\")\n",
    "        x_hat = x_hat.to(\"cpu\")\n",
    "        z = z.detach().to(\"cpu\").numpy()\n",
    "\n",
    "        valid_loss.append(elbo.item())\n",
    "        valid_kl.append(kl.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
